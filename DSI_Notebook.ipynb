{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSI_Notebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYFGrtIJqwUW4mOeZCFx7d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejlibre/Pre-DSI/blob/dev/DSI_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l9GKnWIpp-Qq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "2UfTEbJOqD0k"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Access some historical IMDB data files from the shared drive:\n",
        "https://drive.google.com/drive/folders/1dl6nw0HO9XVrT8dSBJHHn3mDW9EWQpXS?usp=sharing"
      ],
      "metadata": {
        "id": "Cmg1HRs08Z-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wget https://drive.google.com/uc?export=download&id=FILEID\n",
        "#!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID' -O FILENAME\n",
        "\n",
        "#https://drive.google.com/file/d/1wWbLYAsVldXrnOxdJlu4URsPynYykY22/view?usp=sharing title.ratings.tsv.gz\n",
        "#https://drive.google.com/file/d/1ctjnShHP2qNA1l2nKi1l4qWe3hE5SsPH/view?usp=sharing title.basics.tsv.gz\n",
        "#https://drive.google.com/file/d/1jHKr1FOCigt15gVhrNmtHCHRgzzR1ZGc/view?usp=sharing title.akas.tsv.gz\n",
        "\n",
        "\n",
        "#!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1wWbLYAsVldXrnOxdJlu4URsPynYykY22' -O title.ratings.tsv.gz\n",
        "#!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ctjnShHP2qNA1l2nKi1l4qWe3hE5SsPH' -O title.basics.tsv.gz\n",
        "#!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1jHKr1FOCigt15gVhrNmtHCHRgzzR1ZGc' -O title.akas.tsv.gz\n",
        "\n",
        "#gdown --folder --id '1dl6nw0HO9XVrT8dSBJHHn3mDW9EWQpXS'\n",
        "# This chunk works.\n",
        "!pip uninstall --yes gdown # After running this line, restart Colab runtime.\n",
        "\n",
        "!pip install gdown -U --no-cache-dir\n",
        "\n",
        "import gdown\n",
        "#url = 'https://drive.google.com/drive/folders/1dl6nw0HO9XVrT8dSBJHHn3mDW9EWQpXS'\n",
        "#gdown.download_folder(url, quiet=True)\n",
        "\n",
        "\n",
        "!gdown --fuzzy 'https://drive.google.com/file/d/1wWbLYAsVldXrnOxdJlu4URsPynYykY22/view?usp=sharing'\n",
        "!gdown --fuzzy 'https://drive.google.com/file/d/1ctjnShHP2qNA1l2nKi1l4qWe3hE5SsPH/view?usp=sharing'\n",
        "!gdown --fuzzy 'https://drive.google.com/file/d/1jHKr1FOCigt15gVhrNmtHCHRgzzR1ZGc/view?usp=sharing'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rDEzAlFuPOT",
        "outputId": "d01decf1-8b8d-4270-bfe4-f05ebef93574"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: gdown 3.6.4\n",
            "Uninstalling gdown-3.6.4:\n",
            "  Successfully uninstalled gdown-3.6.4\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.2.0.tar.gz (13 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.62.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.4.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.2.0-py3-none-any.whl size=14262 sha256=c81cd7e23bf0a33ac2bc4583fca9ccd19c0b2fb5433ddc690924b1aad0839b40\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gt7q2j90/wheels/8c/17/ff/58721d1fabdb87c21a0529948cf39e2be9af90ddbe4ad65944\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown\n",
            "Successfully installed gdown-4.2.0\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wWbLYAsVldXrnOxdJlu4URsPynYykY22\n",
            "To: /content/title.ratings.tsv.gz\n",
            "100% 4.32M/4.32M [00:00<00:00, 17.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ctjnShHP2qNA1l2nKi1l4qWe3hE5SsPH\n",
            "To: /content/title.basics.tsv.gz\n",
            "100% 96.1M/96.1M [00:01<00:00, 54.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jHKr1FOCigt15gVhrNmtHCHRgzzR1ZGc\n",
            "To: /content/title.akas.tsv.gz\n",
            "100% 54.1M/54.1M [00:00<00:00, 61.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gunzip *.gz\n",
        "!ls -latr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnvHr1FXzrco",
        "outputId": "e067884a-1a38-4fba-e57c-92e793915c8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 632256\n",
            "drwxr-xr-x 4 root root      4096 Dec 23 14:32 .config\n",
            "drwxr-xr-x 1 root root      4096 Dec 23 14:32 sample_data\n",
            "drwxr-xr-x 1 root root      4096 Jan  9 18:00 ..\n",
            "-rw-r--r-- 1 root root  14866228 Jan  9 18:02 title.ratings.tsv\n",
            "-rw-r--r-- 1 root root 452106547 Jan  9 18:02 title.basics.tsv\n",
            "-rw-r--r-- 1 root root 180436875 Jan  9 18:02 title.akas.tsv\n",
            "drwxr-xr-x 1 root root      4096 Jan  9 18:02 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Read the files 'title.basics.tsv.gz', 'title.akas.tsv.gz' and 'title.ratings.tsv.gz' into three separate dataframes using the read_csv method in Pandas.\n"
      ],
      "metadata": {
        "id": "iDIFx61t8ixW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ratings = pd.read_csv('./title.ratings.tsv')\n",
        "#basics = pd.read_csv('./title.basics.tsv')\n",
        "#akas = pd.read_csv('./title.akas.tsv')\n",
        "# parse error, need to specify delimiter TAB\n",
        "#ParserError: '\t' expected after '\"' : quotes used in cells so use argument quoting=3\n",
        "ratings = pd.read_csv(\"./title.ratings.tsv\", delimiter=\"\\t\", engine=\"python\", quoting=3)\n",
        "basics = pd.read_csv(\"./title.basics.tsv\", delimiter=\"\\t\", engine=\"python\", quoting=3)\n",
        "akas = pd.read_csv(\"./title.akas.tsv\", delimiter=\"\\t\", engine=\"python\", quoting=3)\n"
      ],
      "metadata": {
        "id": "vh66EtZkzz3y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enxk2SMB06sP",
        "outputId": "47f8dbc4-9b81-49d9-8837-4ed14bd776a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tconst           874203\n",
              "averageRating    874203\n",
              "numVotes         874203\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basics.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C83wvEgb9rfj",
        "outputId": "d8bc95ff-2b8f-4658-da00-f0928c1d55f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tconst            5330276\n",
              "titleType         5330276\n",
              "primaryTitle      5330270\n",
              "originalTitle     5330270\n",
              "isAdult           5330276\n",
              "startYear         5330276\n",
              "endYear           5330276\n",
              "runtimeMinutes    5330276\n",
              "genres            5330276\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "akas.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WICuHaJT9vhj",
        "outputId": "1400bcf4-e6fe-4f11-b004-8aa84be2b3db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "titleId            3674735\n",
              "ordering           3674735\n",
              "title              3674735\n",
              "region             3674678\n",
              "language           3674735\n",
              "types              3674735\n",
              "attributes         3674735\n",
              "isOriginalTitle    3674735\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = ratings.drop_duplicates()\n",
        "basics = basics.drop_duplicates()\n",
        "akas = akas.drop_duplicates()"
      ],
      "metadata": {
        "id": "uhlxff6a92vZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP4VDtFG-DYY",
        "outputId": "3c6dcf2a-3e41-4e89-c9b5-f06aa11a2fc0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tconst           874203\n",
              "averageRating    874203\n",
              "numVotes         874203\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basics.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JSBo-Ho-F-S",
        "outputId": "14d04a44-6c4f-4bb0-aad0-ee35a3150347"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tconst            5330276\n",
              "titleType         5330276\n",
              "primaryTitle      5330270\n",
              "originalTitle     5330270\n",
              "isAdult           5330276\n",
              "startYear         5330276\n",
              "endYear           5330276\n",
              "runtimeMinutes    5330276\n",
              "genres            5330276\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "akas.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh9_7_qa-H1I",
        "outputId": "27690968-5cf2-4f93-9550-6382972d1f83"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "titleId            3674735\n",
              "ordering           3674735\n",
              "title              3674735\n",
              "region             3674678\n",
              "language           3674735\n",
              "types              3674735\n",
              "attributes         3674735\n",
              "isOriginalTitle    3674735\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.0 Using the Pandas 'merge' method, combine all three dataframes using the Title ID (titleID or tconst) to perform the merge and save it into a new dataframe.\n",
        "3.1 How many lines does the resulting dataframe have if you use an inner merge or outer merge? Make sure you understand the difference.\n",
        "3.2 Using the unique() method, compute how many different 'titleTypes' there are\n"
      ],
      "metadata": {
        "id": "LDKdNXz6-Qhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merge_inner = ratings\n",
        "merge_inner = merge_inner.merge(basics, how='inner', left_on='tconst', right_on='tconst')\n",
        "merge_inner = merge_inner.merge(akas, how='inner', left_on='tconst', right_on='titleId')\n",
        "merge_inner.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "384eQVp6BK06",
        "outputId": "8a5c3d3f-261b-4f60-c609-6c807a9e456d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tconst             1885165\n",
              "averageRating      1885165\n",
              "numVotes           1885165\n",
              "titleType          1885165\n",
              "primaryTitle       1885165\n",
              "originalTitle      1885165\n",
              "isAdult            1885165\n",
              "startYear          1885165\n",
              "endYear            1885165\n",
              "runtimeMinutes     1885165\n",
              "genres             1885165\n",
              "titleId            1885165\n",
              "ordering           1885165\n",
              "title              1885165\n",
              "region             1885157\n",
              "language           1885165\n",
              "types              1885165\n",
              "attributes         1885165\n",
              "isOriginalTitle    1885165\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merge_outer = ratings\n",
        "merge_outer = merge_outer.merge(basics, how='outer', left_on='tconst', right_on='tconst')\n",
        "merge_outer = merge_outer.merge(akas, how='outer', left_on='tconst', right_on='titleId')\n",
        "merge_outer.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hx1WdItAA88c",
        "outputId": "6364c923-6c98-4644-f986-4e218d5a9d9d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tconst             6910572\n",
              "averageRating      2133310\n",
              "numVotes           2133310\n",
              "titleType          6910572\n",
              "primaryTitle       6910566\n",
              "originalTitle      6910566\n",
              "isAdult            6910572\n",
              "startYear          6910572\n",
              "endYear            6910572\n",
              "runtimeMinutes     6910572\n",
              "genres             6910572\n",
              "titleId            3674735\n",
              "ordering           3674735\n",
              "title              3674735\n",
              "region             3674678\n",
              "language           3674735\n",
              "types              3674735\n",
              "attributes         3674735\n",
              "isOriginalTitle    3674735\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merge_inner.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "NIUHcrDqFUKV",
        "outputId": "d2378fdb-81b7-465a-8b43-f177b78d3dfc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-990a8826-900a-4bdc-bebc-9a358a887afa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tconst</th>\n",
              "      <th>averageRating</th>\n",
              "      <th>numVotes</th>\n",
              "      <th>titleType</th>\n",
              "      <th>primaryTitle</th>\n",
              "      <th>originalTitle</th>\n",
              "      <th>isAdult</th>\n",
              "      <th>startYear</th>\n",
              "      <th>endYear</th>\n",
              "      <th>runtimeMinutes</th>\n",
              "      <th>genres</th>\n",
              "      <th>titleId</th>\n",
              "      <th>ordering</th>\n",
              "      <th>title</th>\n",
              "      <th>region</th>\n",
              "      <th>language</th>\n",
              "      <th>types</th>\n",
              "      <th>attributes</th>\n",
              "      <th>isOriginalTitle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tt0000001</td>\n",
              "      <td>5.8</td>\n",
              "      <td>1422</td>\n",
              "      <td>short</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>0</td>\n",
              "      <td>1894</td>\n",
              "      <td>\\N</td>\n",
              "      <td>1</td>\n",
              "      <td>Documentary,Short</td>\n",
              "      <td>tt0000001</td>\n",
              "      <td>1</td>\n",
              "      <td>Carmencita - spanyol tánc</td>\n",
              "      <td>HU</td>\n",
              "      <td>\\N</td>\n",
              "      <td>imdbDisplay</td>\n",
              "      <td>\\N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tt0000001</td>\n",
              "      <td>5.8</td>\n",
              "      <td>1422</td>\n",
              "      <td>short</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>0</td>\n",
              "      <td>1894</td>\n",
              "      <td>\\N</td>\n",
              "      <td>1</td>\n",
              "      <td>Documentary,Short</td>\n",
              "      <td>tt0000001</td>\n",
              "      <td>2</td>\n",
              "      <td>Карменсита</td>\n",
              "      <td>RU</td>\n",
              "      <td>\\N</td>\n",
              "      <td>\\N</td>\n",
              "      <td>\\N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tt0000001</td>\n",
              "      <td>5.8</td>\n",
              "      <td>1422</td>\n",
              "      <td>short</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>0</td>\n",
              "      <td>1894</td>\n",
              "      <td>\\N</td>\n",
              "      <td>1</td>\n",
              "      <td>Documentary,Short</td>\n",
              "      <td>tt0000001</td>\n",
              "      <td>3</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>US</td>\n",
              "      <td>\\N</td>\n",
              "      <td>\\N</td>\n",
              "      <td>\\N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tt0000001</td>\n",
              "      <td>5.8</td>\n",
              "      <td>1422</td>\n",
              "      <td>short</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>0</td>\n",
              "      <td>1894</td>\n",
              "      <td>\\N</td>\n",
              "      <td>1</td>\n",
              "      <td>Documentary,Short</td>\n",
              "      <td>tt0000001</td>\n",
              "      <td>4</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>\\N</td>\n",
              "      <td>\\N</td>\n",
              "      <td>original</td>\n",
              "      <td>\\N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tt0000002</td>\n",
              "      <td>6.4</td>\n",
              "      <td>168</td>\n",
              "      <td>short</td>\n",
              "      <td>Le clown et ses chiens</td>\n",
              "      <td>Le clown et ses chiens</td>\n",
              "      <td>0</td>\n",
              "      <td>1892</td>\n",
              "      <td>\\N</td>\n",
              "      <td>5</td>\n",
              "      <td>Animation,Short</td>\n",
              "      <td>tt0000002</td>\n",
              "      <td>1</td>\n",
              "      <td>Le clown et ses chiens</td>\n",
              "      <td>\\N</td>\n",
              "      <td>\\N</td>\n",
              "      <td>original</td>\n",
              "      <td>\\N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-990a8826-900a-4bdc-bebc-9a358a887afa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-990a8826-900a-4bdc-bebc-9a358a887afa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-990a8826-900a-4bdc-bebc-9a358a887afa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      tconst  averageRating  numVotes  ...        types attributes isOriginalTitle\n",
              "0  tt0000001            5.8      1422  ...  imdbDisplay         \\N               0\n",
              "1  tt0000001            5.8      1422  ...           \\N         \\N               0\n",
              "2  tt0000001            5.8      1422  ...           \\N         \\N               0\n",
              "3  tt0000001            5.8      1422  ...     original         \\N               1\n",
              "4  tt0000002            6.4       168  ...     original         \\N               1\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merge_outer.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "Eo2vSo3uFb6v",
        "outputId": "05aaeb96-a480-4a69-b962-0c5762ed2bb2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dda2f9e1-21cd-4af9-9e10-f35b012cfbba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tconst</th>\n",
              "      <th>averageRating</th>\n",
              "      <th>numVotes</th>\n",
              "      <th>titleType</th>\n",
              "      <th>primaryTitle</th>\n",
              "      <th>originalTitle</th>\n",
              "      <th>isAdult</th>\n",
              "      <th>startYear</th>\n",
              "      <th>endYear</th>\n",
              "      <th>runtimeMinutes</th>\n",
              "      <th>genres</th>\n",
              "      <th>titleId</th>\n",
              "      <th>ordering</th>\n",
              "      <th>title</th>\n",
              "      <th>region</th>\n",
              "      <th>language</th>\n",
              "      <th>types</th>\n",
              "      <th>attributes</th>\n",
              "      <th>isOriginalTitle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tt0000001</td>\n",
              "      <td>5.8</td>\n",
              "      <td>1422.0</td>\n",
              "      <td>short</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1894</td>\n",
              "      <td>\\N</td>\n",
              "      <td>1</td>\n",
              "      <td>Documentary,Short</td>\n",
              "      <td>tt0000001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Carmencita - spanyol tánc</td>\n",
              "      <td>HU</td>\n",
              "      <td>\\N</td>\n",
              "      <td>imdbDisplay</td>\n",
              "      <td>\\N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tt0000001</td>\n",
              "      <td>5.8</td>\n",
              "      <td>1422.0</td>\n",
              "      <td>short</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1894</td>\n",
              "      <td>\\N</td>\n",
              "      <td>1</td>\n",
              "      <td>Documentary,Short</td>\n",
              "      <td>tt0000001</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Карменсита</td>\n",
              "      <td>RU</td>\n",
              "      <td>\\N</td>\n",
              "      <td>\\N</td>\n",
              "      <td>\\N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tt0000001</td>\n",
              "      <td>5.8</td>\n",
              "      <td>1422.0</td>\n",
              "      <td>short</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1894</td>\n",
              "      <td>\\N</td>\n",
              "      <td>1</td>\n",
              "      <td>Documentary,Short</td>\n",
              "      <td>tt0000001</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>US</td>\n",
              "      <td>\\N</td>\n",
              "      <td>\\N</td>\n",
              "      <td>\\N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tt0000001</td>\n",
              "      <td>5.8</td>\n",
              "      <td>1422.0</td>\n",
              "      <td>short</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1894</td>\n",
              "      <td>\\N</td>\n",
              "      <td>1</td>\n",
              "      <td>Documentary,Short</td>\n",
              "      <td>tt0000001</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Carmencita</td>\n",
              "      <td>\\N</td>\n",
              "      <td>\\N</td>\n",
              "      <td>original</td>\n",
              "      <td>\\N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tt0000002</td>\n",
              "      <td>6.4</td>\n",
              "      <td>168.0</td>\n",
              "      <td>short</td>\n",
              "      <td>Le clown et ses chiens</td>\n",
              "      <td>Le clown et ses chiens</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1892</td>\n",
              "      <td>\\N</td>\n",
              "      <td>5</td>\n",
              "      <td>Animation,Short</td>\n",
              "      <td>tt0000002</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Le clown et ses chiens</td>\n",
              "      <td>\\N</td>\n",
              "      <td>\\N</td>\n",
              "      <td>original</td>\n",
              "      <td>\\N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dda2f9e1-21cd-4af9-9e10-f35b012cfbba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dda2f9e1-21cd-4af9-9e10-f35b012cfbba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dda2f9e1-21cd-4af9-9e10-f35b012cfbba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      tconst  averageRating  numVotes  ...        types attributes isOriginalTitle\n",
              "0  tt0000001            5.8    1422.0  ...  imdbDisplay         \\N               0\n",
              "1  tt0000001            5.8    1422.0  ...           \\N         \\N               0\n",
              "2  tt0000001            5.8    1422.0  ...           \\N         \\N               0\n",
              "3  tt0000001            5.8    1422.0  ...     original         \\N               1\n",
              "4  tt0000002            6.4     168.0  ...     original         \\N               1\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titleTypes = merge_inner.titleType.unique()\n",
        "print(titleTypes)\n",
        "print(titleTypes.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAaj0O_NJ3ns",
        "outputId": "64c89f7a-b25f-409a-a0cb-7d6489aeb3b5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['short' 'movie' 'tvMovie' 'tvSeries' 'tvEpisode' 'tvShort' 'tvMiniSeries'\n",
            " 'tvSpecial' 'video' 'videoGame']\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titleTypes = merge_outer.titleType.unique()\n",
        "print(titleTypes)\n",
        "print(titleTypes.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wetn_xidJ9I5",
        "outputId": "7e67445f-4494-4a7e-eaba-8cd64d4f7316"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['short' 'movie' 'tvMovie' 'tvSeries' 'tvEpisode' 'tvShort' 'tvMiniSeries'\n",
            " 'tvSpecial' 'video' 'videoGame' nan]\n",
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Make a new dataframe from step 3 by selecting only rows corresponding to English-language films ('en') OR US-region films ('US') AND only those that are \n",
        "movies (using the 'titleType' column). Put the resulting data into a new dataframe; call it df_new."
      ],
      "metadata": {
        "id": "JkONO8BuZCUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merge_inner.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7COylJlqWdQ",
        "outputId": "3e50d6c8-4c20-442b-e002-f755ea92e4d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['tconst', 'averageRating', 'numVotes', 'titleType', 'primaryTitle',\n",
              "       'originalTitle', 'isAdult', 'startYear', 'endYear', 'runtimeMinutes',\n",
              "       'genres', 'titleId', 'ordering', 'title', 'region', 'language', 'types',\n",
              "       'attributes', 'isOriginalTitle'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merge_inner.titleType.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlDMjRIfqaPR",
        "outputId": "310bcbf9-78d9-49fb-fb6d-a4bdb10b5b2c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['short', 'movie', 'tvMovie', 'tvSeries', 'tvEpisode', 'tvShort',\n",
              "       'tvMiniSeries', 'tvSpecial', 'video', 'videoGame'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merge_inner.language.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keopbVzUqeQZ",
        "outputId": "6871170a-d676-4823-c4a2-cbfa40d476e6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\\\N', 'sv', 'en', 'tr', 'es', 'sr', 'cs', 'fa', 'fr', 'bg', 'ca',\n",
              "       'nl', 'qbn', 'pt', 'ru', 'qbp', 'ar', 'rn', 'de', 'yi', 'uk', 'ka',\n",
              "       'he', 'hr', 'sl', 'tg', 'sk', 'cmn', 'kk', 'da', 'el', 'fi', 'it',\n",
              "       'gsw', 'pl', 'mr', 'qbo', 'gl', 'ms', 'th', 'ta', 'af', 'la', 'hy',\n",
              "       'hi', 'ur', 'yue', 'te', 'bn', 'lt', 'mk', 'et', 'gd', 'tl', 'lv',\n",
              "       'bs', 'cy', 'id', 'qal', 'goh', 'eu', 'ml', 'ro', 'hu', 'pa', 'uz',\n",
              "       'ja', 'wo', 'no', 'is', 'sq', 'vi', 'ga', 'gu', 'nqo', 'kn', 'xh',\n",
              "       'mi', 'ps', 'az', 'ky', 'fro', 'myv', 'ko', 'iu', 'st', 'zu', 'tn',\n",
              "       'zh', 'ku'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merge_inner.region.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoG616TNqguC",
        "outputId": "c900a839-9046-415d-c89e-04089b38cf6a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['HU', 'RU', 'US', '\\\\N', 'FR', 'RO', 'GB', 'PT', 'ES', 'UY', 'DE',\n",
              "       'IT', 'FI', 'PL', 'AR', 'BR', 'XWW', 'TR', 'DK', 'XEU', 'SK', 'CZ',\n",
              "       'SE', 'MX', 'GR', 'RS', 'XYU', 'AT', 'VE', 'CSHH', 'JP', 'AU',\n",
              "       'NL', 'SI', 'NO', 'IR', 'UA', 'CA', 'CO', 'BG', 'BE', 'IN', 'DZ',\n",
              "       'BF', 'XWG', 'NZ', 'VN', 'SUHH', 'EE', 'IS', 'DDDE', 'HR', 'CL',\n",
              "       'LT', 'EG', 'GE', 'CH', 'PA', 'HK', 'CN', 'XSI', 'IE', 'XSA', 'PE',\n",
              "       'IL', 'CU', 'KR', 'BA', 'BUMM', 'YUCS', 'XPI', 'BJ', 'PR', 'MY',\n",
              "       'CM', 'AZ', 'ZA', 'TH', 'BO', 'DO', 'AL', 'EC', 'SG', 'LV', 'MA',\n",
              "       'LI', 'LU', 'ID', 'PH', 'MZ', 'BM', 'PY', 'TW', 'JM', 'MD', 'LB',\n",
              "       'TM', 'GL', 'MK', 'CR', 'TN', 'JO', 'KG', 'PK', 'LK', 'GT', 'XAS',\n",
              "       'SN', 'TJ', 'NE', 'CI', 'MC', 'GH', 'TT', 'BS', 'SY', 'AO', 'KH',\n",
              "       'GA', 'SV', 'MR', 'CY', 'ET', 'ML', 'NG', 'UZ', 'LY', 'SR', 'AM',\n",
              "       'PG', 'IQ', 'BW', 'NI', 'ZM', 'CG', 'KZ', 'KP', 'XKO', 'GI', 'LA',\n",
              "       'GW', 'BD', 'ZW', 'NP', 'BY', 'MN', 'FO', 'PS', 'MO', 'VDVN', 'GN',\n",
              "       'AW', 'KW', 'HT', 'TZ', 'SL', 'SM', 'AF', 'TO', 'BT', 'MT', 'TG',\n",
              "       'HN', 'AD', 'ZRCD', 'GY', 'CSXX', 'ER', nan, 'SA', 'SO', 'IM',\n",
              "       'MU', 'BH', 'KE', 'GP', 'RW', 'TD', 'XKV', 'CV', 'AE', 'SD', 'AG',\n",
              "       'NU', 'OM', 'CD', 'QA', 'BB', 'YE', 'LS', 'LC', 'ME', 'MV', 'BI',\n",
              "       'MH', 'VI', 'DM', 'XNA', 'BZ', 'FJ', 'MW', 'LR', 'SZ', 'UG', 'MG',\n",
              "       'AN', 'VU', 'GU', 'MM', 'TV', 'WS', 'NC', 'BN', 'VA', 'GQ', 'TL',\n",
              "       'MQ', 'GM', 'PW', 'PF', 'GD', 'CF', 'RE', 'SB'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merge_inner[((merge_inner[\"language\"]==\"en\") | (merge_inner[\"region\"]==\"US\")) & (merge_inner[\"titleType\"]==\"movie\")].loc[:,[\"primaryTitle\",\"region\",\"language\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wspNCcxWqtxL",
        "outputId": "6ee3b19e-8b85-4ec1-bd26-04f908c78d33"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0d58c7ed-6fa3-491e-abf6-55f604407534\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>primaryTitle</th>\n",
              "      <th>region</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Miss Jerry</td>\n",
              "      <td>US</td>\n",
              "      <td>\\N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>574</th>\n",
              "      <td>The Corbett-Fitzsimmons Fight</td>\n",
              "      <td>US</td>\n",
              "      <td>\\N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1446</th>\n",
              "      <td>Hamlet</td>\n",
              "      <td>US</td>\n",
              "      <td>\\N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1520</th>\n",
              "      <td>The Fairylogue and Radio-Plays</td>\n",
              "      <td>US</td>\n",
              "      <td>\\N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1797</th>\n",
              "      <td>Hamlet, Prince of Denmark</td>\n",
              "      <td>US</td>\n",
              "      <td>\\N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1885040</th>\n",
              "      <td>Temporary Difficulties</td>\n",
              "      <td>US</td>\n",
              "      <td>\\N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1885103</th>\n",
              "      <td>Bearer</td>\n",
              "      <td>XWW</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1885112</th>\n",
              "      <td>Tuulte tahutud maa</td>\n",
              "      <td>XWW</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1885138</th>\n",
              "      <td>Aickarakkonathe Bhishaguaranmaar</td>\n",
              "      <td>IN</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1885140</th>\n",
              "      <td>What Have We Done to Deserve This?</td>\n",
              "      <td>XWW</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>179685 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d58c7ed-6fa3-491e-abf6-55f604407534')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d58c7ed-6fa3-491e-abf6-55f604407534 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d58c7ed-6fa3-491e-abf6-55f604407534');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                               primaryTitle region language\n",
              "51                               Miss Jerry     US       \\N\n",
              "574           The Corbett-Fitzsimmons Fight     US       \\N\n",
              "1446                                 Hamlet     US       \\N\n",
              "1520         The Fairylogue and Radio-Plays     US       \\N\n",
              "1797              Hamlet, Prince of Denmark     US       \\N\n",
              "...                                     ...    ...      ...\n",
              "1885040              Temporary Difficulties     US       \\N\n",
              "1885103                              Bearer    XWW       en\n",
              "1885112                  Tuulte tahutud maa    XWW       en\n",
              "1885138    Aickarakkonathe Bhishaguaranmaar     IN       en\n",
              "1885140  What Have We Done to Deserve This?    XWW       en\n",
              "\n",
              "[179685 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = merge_inner[((merge_inner[\"language\"]==\"en\") | (merge_inner[\"region\"]==\"US\")) & (merge_inner[\"titleType\"]==\"movie\")]"
      ],
      "metadata": {
        "id": "5CmUA9taZLb8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Add a new column to df_new with column title 'log10Votes' which gives the log_10 number of the 'numVotes' column.\n"
      ],
      "metadata": {
        "id": "k7ncRaierFS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new[\"numVotes\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwhH8PXNrAXr",
        "outputId": "03652145-28de-44d0-9c81-444e80b4e0e7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51          70\n",
              "574        266\n",
              "1446        10\n",
              "1520        26\n",
              "1797        16\n",
              "          ... \n",
              "1885040     20\n",
              "1885103      9\n",
              "1885112     17\n",
              "1885138    213\n",
              "1885140      8\n",
              "Name: numVotes, Length: 179685, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.loc[:,\"log10Votes\"]=np.log10(df_new[\"numVotes\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzd3TrRCrSi-",
        "outputId": "7e90c576-efe3-4826-9367-8b96aa687bb1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[key] = _infer_fill_value(value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_new[\"log10Votes\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0INo2tOu0g-",
        "outputId": "f5c41935-00aa-4eb8-bb1a-702108822d86"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51         1.845098\n",
              "574        2.424882\n",
              "1446       1.000000\n",
              "1520       1.414973\n",
              "1797       1.204120\n",
              "             ...   \n",
              "1885040    1.301030\n",
              "1885103    0.954243\n",
              "1885112    1.230449\n",
              "1885138    2.328380\n",
              "1885140    0.903090\n",
              "Name: log10Votes, Length: 179685, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Lower the case of all text in the 'genres' column.\n"
      ],
      "metadata": {
        "id": "DW59C_zSu40H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new[\"genres\"] = df_new[\"genres\"].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj3ZB3Q4y81n",
        "outputId": "30a843d0-d928-48d6-cc67-3f9f1b64749e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Using Groupby (or other technique) group all data by 'genres' and display the top 10\n",
        "highest genres by\n",
        "\n",
        " 6.1 mean number of log10Votes\n",
        " \n",
        " 6.2 mean averageRating"
      ],
      "metadata": {
        "id": "SqDyCKBGzFVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_rating = df_new.groupby(\"genres\")[\"averageRating\"].mean()\n",
        "mean_rating.sort_values(ascending=False).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edt5tLUQzNQZ",
        "outputId": "75db015e-5e78-4ff9-9b95-5b37e493c101"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "genres\n",
              "documentary,history,western        9.300000\n",
              "history,sport                      9.200000\n",
              "documentary,news,reality-tv        8.800000\n",
              "animation,crime,documentary        8.525000\n",
              "biography,history,music            8.500000\n",
              "adventure,documentary,western      8.433333\n",
              "documentary,drama,thriller         8.433333\n",
              "comedy,mystery,sport               8.400000\n",
              "biography,documentary,talk-show    8.300000\n",
              "action,documentary,fantasy         8.300000\n",
              "Name: averageRating, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_log10Votes = df_new.groupby(\"genres\")[\"log10Votes\"].mean()\n",
        "mean_log10Votes.sort_values(ascending=False).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA5Snrl_73CR",
        "outputId": "d7a3dd33-acdc-46f5-a6c0-e2e8ce6e0b1e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "genres\n",
              "action,fantasy,war            5.405722\n",
              "action,family,romance         4.801753\n",
              "animation,drama,war           4.396304\n",
              "family,music,musical          4.396252\n",
              "documentary,sport,thriller    4.386731\n",
              "action,adventure,sci-fi       4.384822\n",
              "horror,musical,sci-fi         4.340484\n",
              "biography,fantasy,horror      4.271842\n",
              "action,adventure,thriller     4.142012\n",
              "adventure,drama,sci-fi        4.123983\n",
              "Name: log10Votes, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Using ‘groupby’ group all data by averageRating and make a scatter plot of averageRating vs log10Votes."
      ],
      "metadata": {
        "id": "jLXAGE0l-a_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = df_new.groupby(\"averageRating\")[\"log10Votes\"].mean()"
      ],
      "metadata": {
        "id": "il6zfLUo-aMH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "NuYIqewf-jmj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = plt.scatter(ratings.index, ratings.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "50MuHX10C2N_",
        "outputId": "4816bbcb-8d1d-49e1-bd3b-a9eb67863280"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.reset_index().plot(kind='scatter', x='averageRating', y='log10Votes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "HAeWsV4LC5_T",
        "outputId": "1b8b68b3-e1e1-4d62-b6b1-a3cb8488535b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f11806f9b10>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1Gk9a8VAGZmV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Perform linear regression on your data (averageRating vs log10Votes) created in the previous step in three different ways:\n",
        "\n",
        "8.1 Using sklearn\n",
        "\n",
        "8.2 Using scipy\n",
        "\n",
        "8.3 Using pytorch\n"
      ],
      "metadata": {
        "id": "xZnx0jTKGaMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n"
      ],
      "metadata": {
        "id": "_ohGzJoqGeUo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract x and y arrays\n",
        "data = ratings.reset_index()\n",
        "\n",
        "train = data.sample(frac=0.8, random_state=25)\n",
        "test = data.drop(train.index)\n",
        "\n",
        "x_train = train[\"averageRating\"].to_numpy().reshape(-1,1)\n",
        "y_train = train[\"log10Votes\"].to_numpy().reshape(-1,1)\n",
        "\n",
        "x_test = test[\"averageRating\"].to_numpy().reshape(-1,1)\n",
        "y_test = test[\"log10Votes\"].to_numpy().reshape(-1,1)"
      ],
      "metadata": {
        "id": "sCzxmlvGOxjZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# linear regression using scikitlearn\n",
        "\n",
        "reg = LinearRegression().fit(x_train, y_train)\n",
        "print(\"Coefficients: \\n\", reg.coef_)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = reg.predict(x_test)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv_EqKVVPdeN",
        "outputId": "3a15e331-4f30-4ba5-b36f-254aeb9099d5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: \n",
            " [[-0.0828916]]\n",
            "Mean squared error: 0.15\n",
            "Coefficient of determination: -0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# linear regression using scipy\n",
        "x_train2 = np.concatenate( x_train, axis=0 )\n",
        "y_train2 = np.concatenate( y_train, axis=0 )\n",
        "\n",
        "reg2 = stats.linregress(x_train2, y_train2)\n",
        "print(\"Coefficients: \\n\", reg2.slope)\n",
        "\n",
        "# Evaluate\n",
        "y_pred2 = reg2.intercept + reg2.slope * x_test\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred2))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOmjUfc7VE98",
        "outputId": "f5133800-0fa9-4147-cc93-df2ba19e227e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: \n",
            " -0.08289160469409297\n",
            "Mean squared error: 0.15\n",
            "Coefficient of determination: -0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# linear regression using pytorch\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "class linearRegression(torch.nn.Module):\n",
        "    def __init__(self, inputSize, outputSize):\n",
        "        super(linearRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n",
        "\n",
        "inputDim = 1        # takes variable 'x' \n",
        "outputDim = 1       # takes variable 'y'\n",
        "learningRate = 0.01 \n",
        "epochs = 10000\n",
        "\n",
        "model = linearRegression(inputDim, outputDim)\n",
        "\n",
        "criterion = torch.nn.MSELoss() \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n"
      ],
      "metadata": {
        "id": "ctPeyN3SZUBy"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_values_train = np.array(x_train, dtype=np.float32)\n",
        "y_values_train = np.array(y_train, dtype=np.float32)"
      ],
      "metadata": {
        "id": "TTzEaJGLB4X6"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset parameters before training\n",
        "for layer in model.children():\n",
        "    if hasattr(layer, 'reset_parameters'):\n",
        "        layer.reset_parameters()\n",
        "\n",
        "# Training neural network\n",
        "for epoch in range(epochs):\n",
        "    # Converting inputs and labels to Variable\n",
        "    inputs = Variable(torch.from_numpy(x_values_train))\n",
        "    labels = Variable(torch.from_numpy(y_values_train))\n",
        "\n",
        "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # get output from the model, given the inputs\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # get loss for the predicted output\n",
        "    loss = criterion(outputs, labels)\n",
        "    print(loss)\n",
        "    # get gradients w.r.t to parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tLs4qykB5MF",
        "outputId": "6a49c463-365b-4621-ecc4-f903897f534e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7500, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7501, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7502, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7503, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7504, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7505, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7506, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7507, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7508, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7509, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7510, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7511, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7512, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7513, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7514, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7515, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7516, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7517, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7518, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7519, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7520, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7521, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7522, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7523, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7524, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7525, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7526, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7527, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7528, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7529, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7530, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7531, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7532, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7533, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7534, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7535, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7536, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7537, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7538, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7539, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7540, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7541, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7542, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7543, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7544, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7545, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7546, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7547, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7548, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7549, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7550, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7551, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7552, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7553, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7554, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7555, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7556, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7557, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7558, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7559, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7560, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7561, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7562, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7563, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7564, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7565, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7566, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7567, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7568, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7569, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7570, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7571, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7572, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7573, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7574, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7575, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7576, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7577, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7578, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7579, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7580, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7581, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7582, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7583, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7584, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7585, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7586, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7587, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7588, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7589, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7590, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7591, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7592, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7593, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7594, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7595, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7596, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7597, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7598, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7599, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7600, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7601, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7602, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7603, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7604, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7605, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7606, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7607, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7608, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7609, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7610, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7611, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7612, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7613, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7614, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7615, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7616, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7617, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7618, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7619, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7620, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7621, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7622, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7623, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7624, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7625, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7626, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7627, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7628, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7629, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7630, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7631, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7632, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7633, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7634, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7635, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7636, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7637, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7638, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7639, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7640, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7641, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7642, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7643, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7644, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7645, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7646, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7647, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7648, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7649, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7650, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7651, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7652, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7653, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7654, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7655, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7656, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7657, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7658, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7659, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7660, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7661, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7662, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7663, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7664, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7665, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7666, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7667, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7668, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7669, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7670, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7671, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7672, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7673, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7674, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7675, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7676, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7677, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7678, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7679, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7680, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7681, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7682, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7683, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7684, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7685, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7686, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7687, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7688, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7689, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7690, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7691, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7692, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7693, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7694, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7695, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7696, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7697, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7698, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7699, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7700, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7701, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7702, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7703, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7704, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7705, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7706, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7707, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7708, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7709, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7710, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7711, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7712, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7713, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7714, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7715, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7716, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7717, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7718, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7719, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7720, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7721, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7722, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7723, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7724, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7725, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7726, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7727, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7728, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7729, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7730, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7731, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7732, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7733, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7734, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7735, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7736, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7737, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7738, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7739, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7740, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7741, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7742, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7743, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7744, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7745, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7746, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7747, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7748, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7749, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7750, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7751, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7752, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7753, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7754, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7755, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7756, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7757, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7758, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7759, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7760, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7761, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7762, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7763, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7764, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7765, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7766, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7767, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7768, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7769, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7770, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7771, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7772, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7773, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7774, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7775, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7776, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7777, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7778, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7779, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7780, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7781, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7782, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7783, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7784, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7785, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7786, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7787, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7788, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7789, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7790, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7791, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7792, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7793, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7794, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7795, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7796, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7797, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7798, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7799, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7800, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7801, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7802, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7803, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7804, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7805, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7806, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7807, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7808, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7809, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7810, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7811, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7812, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7813, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7814, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7815, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7816, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7817, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7818, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7819, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7820, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7821, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7822, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7823, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7824, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7825, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7826, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7827, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7828, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7829, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7830, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7831, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7832, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7833, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7834, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7835, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7836, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7837, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7838, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7839, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7840, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7841, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7842, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7843, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7844, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7845, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7846, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7847, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7848, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7849, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7850, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7851, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7852, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7853, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7854, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7855, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7856, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7857, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7858, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7859, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7860, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7861, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7862, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7863, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7864, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7865, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7866, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7867, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7868, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7869, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7870, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7871, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7872, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7873, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7874, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7875, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7876, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7877, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7878, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7879, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7880, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7881, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7882, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7883, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7884, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7885, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7886, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7887, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7888, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7889, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7890, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7891, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7892, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7893, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7894, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7895, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7896, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7897, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7898, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7899, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7900, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7901, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7902, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7903, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7904, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7905, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7906, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7907, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7908, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7909, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7910, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7911, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7912, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7913, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7914, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7915, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7916, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7917, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7918, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7919, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7920, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7921, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7922, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7923, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7924, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7925, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7926, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7927, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7928, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7929, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7930, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7931, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7932, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7933, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7934, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7935, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7936, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7937, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7938, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7939, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7940, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7941, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7942, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7943, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7944, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7945, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7946, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7947, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7948, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7949, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7950, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7951, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7952, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7953, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7954, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7955, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7956, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7957, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7958, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7959, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7960, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7961, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7962, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7963, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7964, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7965, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7966, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7967, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7968, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7969, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7970, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7971, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7972, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7973, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7974, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7975, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7976, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7977, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7978, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7979, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7980, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7981, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7982, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7983, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7984, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7985, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7986, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7987, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7988, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7989, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7990, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7991, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7992, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7993, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7994, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7995, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7996, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7997, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7998, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 7999, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8000, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8001, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8002, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8003, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8004, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8005, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8006, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8007, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8008, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8009, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8010, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8011, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8012, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8013, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8014, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8015, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8016, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8017, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8018, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8019, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8020, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8021, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8022, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8023, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8024, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8025, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8026, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8027, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8028, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8029, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8030, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8031, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8032, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8033, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8034, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8035, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8036, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8037, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8038, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8039, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8040, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8041, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8042, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8043, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8044, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8045, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8046, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8047, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8048, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8049, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8050, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8051, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8052, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8053, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8054, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8055, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8056, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8057, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8058, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8059, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8060, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8061, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8062, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8063, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8064, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8065, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8066, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8067, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8068, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8069, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8070, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8071, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8072, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8073, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8074, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8075, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8076, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8077, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8078, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8079, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8080, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8081, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8082, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8083, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8084, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8085, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8086, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8087, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8088, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8089, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8090, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8091, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8092, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8093, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8094, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8095, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8096, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8097, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8098, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8099, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8100, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8101, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8102, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8103, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8104, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8105, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8106, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8107, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8108, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8109, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8110, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8111, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8112, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8113, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8114, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8115, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8116, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8117, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8118, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8119, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8120, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8121, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8122, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8123, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8124, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8125, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8126, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8127, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8128, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8129, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8130, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8131, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8132, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8133, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8134, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8135, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8136, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8137, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8138, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8139, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8140, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8141, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8142, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8143, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8144, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8145, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8146, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8147, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8148, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8149, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8150, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8151, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8152, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8153, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8154, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8155, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8156, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8157, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8158, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8159, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8160, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8161, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8162, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8163, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8164, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8165, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8166, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8167, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8168, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8169, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8170, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8171, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8172, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8173, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8174, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8175, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8176, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8177, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8178, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8179, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8180, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8181, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8182, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8183, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8184, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8185, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8186, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8187, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8188, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8189, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8190, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8191, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8192, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8193, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8194, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8195, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8196, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8197, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8198, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8199, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8200, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8201, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8202, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8203, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8204, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8205, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8206, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8207, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8208, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8209, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8210, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8211, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8212, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8213, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8214, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8215, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8216, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8217, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8218, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8219, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8220, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8221, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8222, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8223, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8224, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8225, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8226, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8227, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8228, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8229, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8230, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8231, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8232, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8233, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8234, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8235, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8236, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8237, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8238, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8239, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8240, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8241, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8242, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8243, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8244, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8245, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8246, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8247, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8248, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8249, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8250, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8251, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8252, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8253, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8254, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8255, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8256, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8257, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8258, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8259, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8260, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8261, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8262, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8263, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8264, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8265, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8266, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8267, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8268, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8269, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8270, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8271, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8272, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8273, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8274, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8275, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8276, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8277, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8278, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8279, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8280, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8281, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8282, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8283, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8284, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8285, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8286, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8287, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8288, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8289, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8290, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8291, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8292, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8293, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8294, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8295, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8296, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8297, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8298, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8299, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8300, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8301, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8302, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8303, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8304, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8305, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8306, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8307, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8308, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8309, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8310, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8311, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8312, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8313, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8314, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8315, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8316, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8317, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8318, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8319, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8320, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8321, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8322, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8323, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8324, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8325, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8326, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8327, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8328, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8329, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8330, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8331, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8332, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8333, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8334, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8335, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8336, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8337, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8338, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8339, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8340, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8341, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8342, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8343, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8344, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8345, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8346, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8347, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8348, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8349, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8350, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8351, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8352, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8353, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8354, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8355, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8356, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8357, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8358, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8359, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8360, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8361, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8362, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8363, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8364, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8365, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8366, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8367, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8368, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8369, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8370, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8371, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8372, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8373, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8374, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8375, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8376, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8377, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8378, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8379, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8380, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8381, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8382, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8383, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8384, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8385, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8386, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8387, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8388, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8389, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8390, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8391, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8392, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8393, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8394, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8395, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8396, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8397, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8398, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8399, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8400, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8401, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8402, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8403, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8404, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8405, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8406, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8407, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8408, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8409, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8410, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8411, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8412, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8413, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8414, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8415, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8416, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8417, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8418, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8419, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8420, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8421, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8422, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8423, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8424, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8425, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8426, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8427, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8428, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8429, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8430, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8431, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8432, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8433, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8434, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8435, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8436, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8437, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8438, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8439, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8440, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8441, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8442, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8443, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8444, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8445, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8446, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8447, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8448, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8449, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8450, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8451, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8452, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8453, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8454, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8455, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8456, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8457, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8458, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8459, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8460, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8461, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8462, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8463, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8464, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8465, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8466, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8467, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8468, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8469, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8470, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8471, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8472, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8473, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8474, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8475, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8476, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8477, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8478, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8479, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8480, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8481, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8482, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8483, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8484, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8485, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8486, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8487, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8488, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8489, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8490, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8491, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8492, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8493, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8494, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8495, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8496, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8497, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8498, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8499, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8500, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8501, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8502, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8503, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8504, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8505, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8506, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8507, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8508, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8509, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8510, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8511, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8512, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8513, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8514, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8515, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8516, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8517, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8518, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8519, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8520, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8521, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8522, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8523, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8524, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8525, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8526, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8527, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8528, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8529, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8530, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8531, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8532, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8533, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8534, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8535, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8536, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8537, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8538, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8539, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8540, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8541, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8542, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8543, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8544, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8545, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8546, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8547, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8548, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8549, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8550, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8551, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8552, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8553, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8554, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8555, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8556, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8557, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8558, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8559, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8560, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8561, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8562, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8563, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8564, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8565, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8566, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8567, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8568, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8569, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8570, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8571, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8572, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8573, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8574, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8575, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8576, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8577, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8578, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8579, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8580, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8581, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8582, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8583, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8584, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8585, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8586, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8587, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8588, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8589, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8590, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8591, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8592, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8593, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8594, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8595, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8596, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8597, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8598, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8599, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8600, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8601, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8602, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8603, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8604, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8605, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8606, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8607, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8608, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8609, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8610, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8611, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8612, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8613, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8614, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8615, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8616, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8617, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8618, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8619, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8620, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8621, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8622, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8623, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8624, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8625, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8626, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8627, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8628, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8629, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8630, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8631, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8632, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8633, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8634, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8635, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8636, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8637, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8638, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8639, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8640, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8641, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8642, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8643, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8644, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8645, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8646, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8647, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8648, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8649, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8650, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8651, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8652, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8653, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8654, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8655, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8656, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8657, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8658, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8659, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8660, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8661, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8662, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8663, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8664, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8665, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8666, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8667, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8668, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8669, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8670, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8671, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8672, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8673, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8674, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8675, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8676, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8677, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8678, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8679, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8680, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8681, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8682, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8683, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8684, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8685, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8686, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8687, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8688, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8689, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8690, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8691, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8692, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8693, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8694, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8695, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8696, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8697, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8698, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8699, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8700, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8701, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8702, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8703, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8704, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8705, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8706, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8707, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8708, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8709, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8710, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8711, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8712, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8713, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8714, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8715, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8716, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8717, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8718, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8719, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8720, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8721, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8722, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8723, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8724, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8725, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8726, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8727, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8728, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8729, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8730, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8731, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8732, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8733, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8734, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8735, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8736, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8737, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8738, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8739, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8740, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8741, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8742, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8743, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8744, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8745, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8746, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8747, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8748, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8749, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8750, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8751, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8752, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8753, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8754, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8755, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8756, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8757, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8758, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8759, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8760, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8761, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8762, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8763, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8764, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8765, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8766, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8767, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8768, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8769, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8770, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8771, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8772, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8773, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8774, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8775, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8776, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8777, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8778, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8779, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8780, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8781, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8782, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8783, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8784, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8785, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8786, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8787, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8788, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8789, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8790, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8791, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8792, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8793, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8794, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8795, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8796, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8797, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8798, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8799, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8800, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8801, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8802, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8803, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8804, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8805, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8806, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8807, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8808, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8809, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8810, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8811, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8812, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8813, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8814, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8815, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8816, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8817, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8818, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8819, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8820, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8821, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8822, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8823, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8824, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8825, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8826, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8827, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8828, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8829, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8830, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8831, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8832, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8833, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8834, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8835, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8836, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8837, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8838, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8839, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8840, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8841, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8842, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8843, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8844, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8845, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8846, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8847, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8848, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8849, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8850, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8851, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8852, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8853, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8854, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8855, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8856, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8857, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8858, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8859, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8860, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8861, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8862, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8863, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8864, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8865, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8866, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8867, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8868, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8869, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8870, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8871, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8872, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8873, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8874, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8875, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8876, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8877, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8878, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8879, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8880, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8881, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8882, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8883, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8884, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8885, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8886, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8887, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8888, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8889, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8890, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8891, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8892, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8893, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8894, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8895, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8896, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8897, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8898, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8899, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8900, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8901, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8902, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8903, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8904, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8905, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8906, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8907, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8908, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8909, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8910, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8911, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8912, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8913, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8914, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8915, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8916, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8917, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8918, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8919, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8920, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8921, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8922, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8923, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8924, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8925, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8926, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8927, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8928, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8929, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8930, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8931, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8932, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8933, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8934, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8935, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8936, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8937, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8938, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8939, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8940, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8941, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8942, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8943, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8944, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8945, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8946, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8947, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8948, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8949, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8950, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8951, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8952, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8953, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8954, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8955, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8956, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8957, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8958, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8959, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8960, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8961, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8962, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8963, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8964, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8965, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8966, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8967, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8968, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8969, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8970, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8971, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8972, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8973, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8974, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8975, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8976, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8977, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8978, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8979, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8980, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8981, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8982, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8983, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8984, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8985, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8986, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8987, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8988, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8989, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8990, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8991, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8992, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8993, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8994, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8995, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8996, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8997, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8998, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 8999, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9000, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9001, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9002, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9003, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9004, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9005, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9006, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9007, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9008, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9009, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9010, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9011, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9012, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9013, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9014, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9015, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9016, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9017, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9018, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9019, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9020, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9021, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9022, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9023, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9024, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9025, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9026, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9027, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9028, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9029, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9030, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9031, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9032, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9033, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9034, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9035, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9036, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9037, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9038, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9039, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9040, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9041, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9042, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9043, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9044, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9045, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9046, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9047, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9048, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9049, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9050, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9051, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9052, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9053, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9054, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9055, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9056, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9057, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9058, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9059, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9060, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9061, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9062, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9063, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9064, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9065, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9066, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9067, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9068, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9069, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9070, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9071, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9072, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9073, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9074, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9075, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9076, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9077, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9078, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9079, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9080, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9081, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9082, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9083, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9084, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9085, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9086, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9087, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9088, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9089, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9090, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9091, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9092, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9093, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9094, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9095, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9096, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9097, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9098, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9099, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9100, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9101, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9102, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9103, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9104, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9105, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9106, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9107, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9108, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9109, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9110, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9111, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9112, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9113, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9114, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9115, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9116, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9117, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9118, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9119, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9120, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9121, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9122, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9123, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9124, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9125, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9126, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9127, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9128, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9129, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9130, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9131, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9132, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9133, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9134, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9135, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9136, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9137, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9138, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9139, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9140, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9141, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9142, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9143, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9144, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9145, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9146, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9147, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9148, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9149, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9150, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9151, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9152, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9153, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9154, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9155, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9156, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9157, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9158, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9159, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9160, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9161, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9162, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9163, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9164, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9165, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9166, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9167, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9168, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9169, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9170, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9171, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9172, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9173, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9174, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9175, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9176, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9177, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9178, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9179, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9180, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9181, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9182, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9183, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9184, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9185, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9186, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9187, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9188, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9189, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9190, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9191, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9192, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9193, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9194, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9195, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9196, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9197, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9198, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9199, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9200, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9201, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9202, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9203, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9204, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9205, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9206, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9207, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9208, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9209, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9210, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9211, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9212, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9213, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9214, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9215, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9216, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9217, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9218, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9219, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9220, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9221, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9222, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9223, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9224, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9225, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9226, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9227, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9228, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9229, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9230, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9231, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9232, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9233, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9234, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9235, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9236, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9237, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9238, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9239, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9240, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9241, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9242, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9243, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9244, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9245, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9246, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9247, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9248, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9249, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9250, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9251, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9252, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9253, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9254, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9255, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9256, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9257, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9258, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9259, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9260, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9261, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9262, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9263, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9264, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9265, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9266, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9267, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9268, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9269, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9270, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9271, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9272, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9273, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9274, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9275, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9276, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9277, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9278, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9279, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9280, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9281, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9282, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9283, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9284, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9285, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9286, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9287, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9288, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9289, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9290, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9291, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9292, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9293, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9294, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9295, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9296, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9297, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9298, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9299, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9300, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9301, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9302, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9303, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9304, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9305, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9306, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9307, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9308, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9309, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9310, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9311, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9312, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9313, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9314, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9315, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9316, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9317, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9318, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9319, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9320, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9321, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9322, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9323, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9324, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9325, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9326, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9327, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9328, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9329, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9330, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9331, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9332, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9333, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9334, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9335, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9336, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9337, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9338, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9339, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9340, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9341, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9342, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9343, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9344, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9345, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9346, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9347, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9348, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9349, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9350, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9351, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9352, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9353, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9354, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9355, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9356, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9357, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9358, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9359, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9360, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9361, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9362, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9363, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9364, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9365, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9366, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9367, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9368, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9369, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9370, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9371, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9372, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9373, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9374, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9375, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9376, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9377, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9378, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9379, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9380, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9381, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9382, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9383, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9384, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9385, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9386, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9387, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9388, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9389, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9390, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9391, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9392, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9393, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9394, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9395, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9396, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9397, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9398, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9399, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9400, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9401, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9402, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9403, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9404, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9405, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9406, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9407, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9408, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9409, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9410, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9411, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9412, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9413, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9414, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9415, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9416, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9417, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9418, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9419, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9420, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9421, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9422, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9423, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9424, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9425, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9426, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9427, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9428, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9429, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9430, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9431, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9432, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9433, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9434, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9435, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9436, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9437, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9438, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9439, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9440, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9441, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9442, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9443, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9444, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9445, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9446, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9447, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9448, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9449, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9450, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9451, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9452, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9453, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9454, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9455, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9456, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9457, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9458, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9459, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9460, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9461, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9462, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9463, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9464, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9465, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9466, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9467, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9468, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9469, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9470, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9471, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9472, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9473, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9474, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9475, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9476, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9477, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9478, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9479, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9480, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9481, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9482, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9483, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9484, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9485, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9486, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9487, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9488, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9489, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9490, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9491, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9492, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9493, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9494, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9495, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9496, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9497, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9498, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9499, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9500, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9501, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9502, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9503, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9504, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9505, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9506, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9507, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9508, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9509, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9510, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9511, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9512, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9513, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9514, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9515, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9516, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9517, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9518, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9519, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9520, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9521, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9522, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9523, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9524, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9525, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9526, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9527, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9528, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9529, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9530, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9531, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9532, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9533, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9534, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9535, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9536, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9537, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9538, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9539, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9540, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9541, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9542, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9543, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9544, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9545, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9546, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9547, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9548, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9549, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9550, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9551, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9552, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9553, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9554, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9555, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9556, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9557, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9558, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9559, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9560, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9561, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9562, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9563, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9564, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9565, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9566, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9567, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9568, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9569, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9570, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9571, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9572, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9573, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9574, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9575, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9576, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9577, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9578, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9579, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9580, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9581, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9582, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9583, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9584, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9585, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9586, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9587, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9588, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9589, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9590, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9591, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9592, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9593, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9594, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9595, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9596, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9597, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9598, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9599, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9600, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9601, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9602, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9603, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9604, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9605, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9606, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9607, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9608, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9609, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9610, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9611, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9612, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9613, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9614, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9615, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9616, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9617, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9618, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9619, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9620, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9621, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9622, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9623, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9624, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9625, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9626, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9627, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9628, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9629, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9630, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9631, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9632, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9633, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9634, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9635, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9636, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9637, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9638, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9639, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9640, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9641, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9642, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9643, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9644, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9645, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9646, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9647, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9648, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9649, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9650, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9651, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9652, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9653, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9654, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9655, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9656, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9657, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9658, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9659, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9660, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9661, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9662, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9663, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9664, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9665, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9666, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9667, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9668, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9669, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9670, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9671, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9672, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9673, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9674, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9675, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9676, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9677, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9678, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9679, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9680, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9681, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9682, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9683, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9684, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9685, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9686, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9687, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9688, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9689, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9690, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9691, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9692, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9693, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9694, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9695, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9696, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9697, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9698, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9699, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9700, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9701, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9702, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9703, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9704, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9705, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9706, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9707, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9708, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9709, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9710, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9711, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9712, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9713, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9714, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9715, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9716, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9717, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9718, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9719, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9720, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9721, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9722, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9723, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9724, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9725, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9726, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9727, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9728, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9729, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9730, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9731, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9732, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9733, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9734, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9735, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9736, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9737, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9738, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9739, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9740, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9741, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9742, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9743, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9744, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9745, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9746, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9747, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9748, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9749, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9750, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9751, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9752, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9753, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9754, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9755, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9756, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9757, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9758, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9759, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9760, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9761, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9762, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9763, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9764, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9765, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9766, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9767, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9768, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9769, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9770, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9771, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9772, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9773, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9774, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9775, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9776, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9777, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9778, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9779, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9780, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9781, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9782, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9783, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9784, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9785, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9786, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9787, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9788, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9789, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9790, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9791, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9792, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9793, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9794, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9795, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9796, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9797, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9798, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9799, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9800, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9801, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9802, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9803, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9804, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9805, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9806, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9807, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9808, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9809, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9810, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9811, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9812, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9813, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9814, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9815, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9816, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9817, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9818, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9819, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9820, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9821, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9822, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9823, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9824, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9825, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9826, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9827, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9828, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9829, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9830, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9831, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9832, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9833, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9834, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9835, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9836, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9837, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9838, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9839, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9840, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9841, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9842, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9843, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9844, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9845, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9846, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9847, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9848, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9849, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9850, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9851, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9852, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9853, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9854, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9855, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9856, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9857, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9858, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9859, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9860, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9861, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9862, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9863, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9864, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9865, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9866, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9867, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9868, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9869, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9870, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9871, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9872, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9873, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9874, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9875, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9876, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9877, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9878, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9879, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9880, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9881, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9882, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9883, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9884, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9885, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9886, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9887, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9888, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9889, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9890, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9891, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9892, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9893, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9894, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9895, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9896, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9897, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9898, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9899, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9900, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9901, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9902, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9903, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9904, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9905, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9906, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9907, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9908, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9909, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9910, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9911, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9912, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9913, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9914, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9915, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9916, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9917, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9918, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9919, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9920, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9921, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9922, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9923, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9924, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9925, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9926, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9927, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9928, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9929, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9930, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9931, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9932, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9933, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9934, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9935, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9936, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9937, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9938, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9939, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9940, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9941, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9942, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9943, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9944, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9945, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9946, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9947, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9948, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9949, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9950, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9951, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9952, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9953, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9954, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9955, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9956, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9957, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9958, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9959, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9960, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9961, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9962, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9963, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9964, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9965, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9966, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9967, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9968, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9969, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9970, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9971, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9972, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9973, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9974, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9975, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9976, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9977, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9978, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9979, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9980, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9981, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9982, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9983, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9984, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9985, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9986, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9987, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9988, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9989, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9990, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9991, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9992, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9993, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9994, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9995, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9996, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9997, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9998, loss 0.10716859251260757\n",
            "tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
            "epoch 9999, loss 0.10716859251260757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_values_test = np.array(x_test, dtype=np.float32)\n",
        "y_values_test = np.array(y_test, dtype=np.float32)\n",
        "with torch.no_grad(): # we don't need gradients in the testing phase\n",
        "        y_pred3 = model(Variable(torch.from_numpy(x_values_test))).data.numpy()\n",
        "print(y_pred3)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred3))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4Fdg9szCiKy",
        "outputId": "1a45d470-9a2d-43df-8932-dfbb551afb3f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.4534466]\n",
            " [2.4368694]\n",
            " [2.4285805]\n",
            " [2.395426 ]\n",
            " [2.3374052]\n",
            " [2.271096 ]\n",
            " [2.2296526]\n",
            " [2.2047868]\n",
            " [2.1384773]\n",
            " [2.097034 ]\n",
            " [2.0887454]\n",
            " [2.047302 ]\n",
            " [2.0058587]\n",
            " [1.9561267]\n",
            " [1.9478381]\n",
            " [1.8898175]\n",
            " [1.8317966]\n",
            " [1.7157555]]\n",
            "Mean squared error: 0.15\n",
            "Coefficient of determination: -0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find slope using scipy least square fitting\n",
        "\n",
        "#print(x_test)\n",
        "#print(y_pred3)\n",
        "\n",
        "reg3 = stats.linregress(x_test.flatten(), y_pred3.flatten())\n",
        "print(\"Coefficients: \\n\", reg3.slope)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqwIEKbWFY_l",
        "outputId": "e422a361-e828-429f-a2a6-20498faf1e8f"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: \n",
            " -0.08288665160574296\n"
          ]
        }
      ]
    }
  ]
}